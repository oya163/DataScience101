{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "    Converts the all the text files inside a folder\n",
    "    into a proper csv format (label, data)\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import unicodecsv as csv\n",
    "import unicodedata as un\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# Change the following for train or test\n",
    "in_path = './data/aclImdb/data/train'\n",
    "out_path= './data/aclImdb/train.csv'\n",
    "\n",
    "counter = 0\n",
    "error_counter = 0\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Prepare dictionary of necessary unicode\n",
    "# Thanks to https://stackoverflow.com/a/11066687/4595807\n",
    "# We want to protect '-'\n",
    "# HYPHEN-MINUS = UNICODE DECIMAL VALUE = 45\n",
    "table = dict.fromkeys(i for i in range(sys.maxunicode) \n",
    "                        if un.category(chr(i)).startswith(('P','N','S','Cf','Cn','Cc')))\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "header = 'label', 'data'\n",
    "\n",
    "with open(out_path, 'wb') as out_file:\n",
    "    writer = csv.writer(out_file, encoding='utf-8')\n",
    "    writer.writerow(header)\n",
    "    label = -1\n",
    "    for root, dirs, files in os.walk(in_path, topdown=True):\n",
    "        \n",
    "        for name in files:\n",
    "            curr_file = os.path.join(root, name)\n",
    "            try:\n",
    "                # Read current file and remove BOM and newline characters\n",
    "                # uf03c and uf03c are invalid unicode characters and don't have any category\n",
    "                # so had to remove manually\n",
    "                fp = open(curr_file, encoding='utf-8-sig').read()\n",
    "                \n",
    "                # Remove html tags\n",
    "                fp = fp.replace('<br />', '')\n",
    "                \n",
    "                # Remove all punctuations\n",
    "                fp = fp.translate(translator)\n",
    "                \n",
    "                # Remove numbers/symbols/invalid chars\n",
    "                fp = fp.translate(table)\n",
    "                \n",
    "                # Conver to lower case\n",
    "                fp = fp.lower()\n",
    "                \n",
    "                # We are not doing word tokenize here for preprocessing\n",
    "                # because the whole data will be read as a string rather than tokens\n",
    "                # when we read it later on\n",
    "                \n",
    "                # Tokenize the word\n",
    "#                 fp = word_tokenize(fp)\n",
    "                \n",
    "                # Remove the stopwords\n",
    "#                 fp = [w for w in fp if not w in stop_words]\n",
    "                \n",
    "                \n",
    "                # Normalize the unicode so that\n",
    "                # canonical-equivalent ones will also have precisely the same binary representation\n",
    "                final_msg = label, fp\n",
    "                \n",
    "                # Write into CSV file format - label, data\n",
    "                writer.writerow(final_msg)\n",
    "\n",
    "                # Counter setup to count file processed\n",
    "                counter = counter + 1\n",
    "#                 break\n",
    "\n",
    "            except IOError as e:\n",
    "                print (\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "                error_counter = error_counter + 1\n",
    "#                 break\n",
    "        label += 1\n",
    "                \n",
    "\n",
    "out_file.close()\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print('Number of files processed: ',counter)\n",
    "print('Number of files error: ',error_counter)\n",
    "\n",
    "print('Time taken in seconds:',(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
