{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uttam\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Author - Oyesh Mann Singh\n",
    "    Date - 11/30/2018\n",
    "    Description \n",
    "        - Usage of Word Embedding\n",
    "        - Deep Learning\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import unicodecsv as csv\n",
    "import unicodedata as un\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Read all files into one corpus file\n",
    "    Break down each sentence into new line\n",
    "    Remove punctuation except selective punctuation\n",
    "    Lowercase\n",
    "    Replace numbers with <num>\n",
    "    Do not remove stop words\n",
    "    Remove '.'\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = './data/aclImdb/data/'\n",
    "out_file = './data/raw_corpus.txt'\n",
    "\n",
    "# Create a corpus and remove html break \n",
    "with open(out_file, 'w', encoding='utf8') as out_f:\n",
    "    for root, dirs, files in os.walk(in_path, topdown=True):\n",
    "        if(len(files) > 0):\n",
    "            for each_file in files:\n",
    "                file_path = os.path.join(root, each_file)\n",
    "                content = open(file_path, encoding='utf-8-sig').read().replace('<br />', '')\n",
    "                out_f.write(content)\n",
    "\n",
    "out_f.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = open(out_file, encoding='utf-8').read().replace('<br />', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# https://stackoverflow.com/a/31505798/4595807\n",
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "numbers = \"([0-9])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    \n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(numbers,\"<num>\",text)\n",
    "\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\"<stop>\")\n",
    "    text = text.replace(\"?\",\"<stop>\")\n",
    "    text = text.replace(\"!\",\"<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    text = text.replace(\"<br />\",\"\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences if len(s) > 1]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = split_into_sentences(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once again Mr. Costner has dragged out a movie for far longer than necessary', 'Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters', \"Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care\", 'The character we should really care about is a very cocky, overconfident Ashton Kutcher', \"The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet\", 'His only obstacle appears to be winning over Costner', \"Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts\", 'We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing', 'No magic here, it was all I could do to keep from turning it off an hour in', 'This is an example of why the majority of action films are the same', \"Generic and boring, there's really nothing worth watching here\", \"A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well\", \"Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal\", \"Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film\", 'And why the heck does he always play the exact same character', \"From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying\", 'Overall, this is second-rate action trash', 'There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script', 'The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite', '<num>/<num><num>']\n"
     ]
    }
   ],
   "source": [
    "print(sent[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
