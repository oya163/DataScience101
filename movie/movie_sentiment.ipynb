{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./data/aclImdb/train/pos/0_9.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import unicodecsv as csv\n",
    "import unicodedata as un\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "in_path = './data/aclImdb/train/'\n",
    "out_path= './data/aclImdb/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files processed:  25000\n",
      "Number of files error:  0\n",
      "Time taken in seconds: 8.349965572357178\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "error_counter = 0\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "label = 0\n",
    "\n",
    "# Prepare dictionary of necessary unicode\n",
    "# Thanks to https://stackoverflow.com/a/11066687/4595807\n",
    "# We want to protect '-'\n",
    "# HYPHEN-MINUS = UNICODE DECIMAL VALUE = 45\n",
    "table = dict.fromkeys(i for i in range(sys.maxunicode) \n",
    "                        if un.category(chr(i)).startswith(('P','N','S','Cf','Cn','Cc')))\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "header = 'label', 'data'\n",
    "\n",
    "with open(out_path, 'wb') as out_file:\n",
    "    writer = csv.writer(out_file, encoding='utf-8')\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for root, dirs, files in os.walk(in_path, topdown=True):\n",
    "        \n",
    "        for name in files:\n",
    "            curr_file = os.path.join(root, name)\n",
    "            try:\n",
    "                # Read current file and remove BOM and newline characters\n",
    "                # uf03c and uf03c are invalid unicode characters and don't have any category\n",
    "                # so had to remove manually\n",
    "                fp = open(curr_file, encoding='utf-8-sig').read()\n",
    "                \n",
    "                # Remove html tags\n",
    "                fp = fp.replace('<br />', '')\n",
    "                \n",
    "                # Remove all punctuations\n",
    "                fp = fp.translate(translator)\n",
    "                \n",
    "                # Remove numbers/symbols/invalid chars\n",
    "                fp = fp.translate(table)\n",
    "                \n",
    "                # Conver to lower case\n",
    "                fp = fp.lower()\n",
    "                \n",
    "                # Tokenize the word\n",
    "#                 fp = word_tokenize(fp)\n",
    "                \n",
    "                # Remove the stopwords\n",
    "#                 fp = [w for w in fp if not w in stop_words]\n",
    "                \n",
    "                \n",
    "                # Normalize the unicode so that\n",
    "                # canonical-equivalent ones will also have precisely the same binary representation\n",
    "                final_msg = label, fp\n",
    "                \n",
    "                # Write into CSV file format - label, data\n",
    "                writer.writerow(final_msg)\n",
    "\n",
    "                # Counter setup to count file processed\n",
    "                counter = counter + 1\n",
    "#                 break\n",
    "\n",
    "            except IOError as e:\n",
    "                print (\"I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "                error_counter = error_counter + 1\n",
    "#                 break\n",
    "        label += 1\n",
    "                \n",
    "\n",
    "out_file.close()\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print('Number of files processed: ',counter)\n",
    "print('Number of files error: ',error_counter)\n",
    "\n",
    "print('Time taken in seconds:',(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd.read_csv('./data/aclImdb/train.csv')\n",
    "pd_test = pd.read_csv('./data/aclImdb/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>story of a man who has unnatural feelings for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>airport   starts as a brand new luxury  plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this film lacked something i couldn t put my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sorry everyone    i know this is supposed to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>when i was little my parents took me along to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               data\n",
       "0      1  story of a man who has unnatural feelings for ...\n",
       "1      1  airport   starts as a brand new luxury  plane ...\n",
       "2      1  this film lacked something i couldn t put my f...\n",
       "3      1  sorry everyone    i know this is supposed to b...\n",
       "4      1  when i was little my parents took me along to ..."
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in train =  32430009\n",
      "Number of tokens in test =  28877902\n"
     ]
    }
   ],
   "source": [
    "train_token_count = 0\n",
    "test_token_count = 0\n",
    "\n",
    "for each_row in pd_train['data']:\n",
    "    train_token_count += len(each_row)\n",
    "    \n",
    "for each_row in pd_test['data']:\n",
    "    test_token_count += len(each_row)\n",
    "\n",
    "print(\"Number of tokens in train = \", train_token_count)\n",
    "print(\"Number of tokens in test = \", test_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Number of tokens in each sentence in train =  1297.20036\n",
      "Avg Number of tokens in each sentence in test =  1155.11608\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Number of tokens in each sentence in train = \", train_token_count/pd_train.shape[0])\n",
    "print(\"Avg Number of tokens in each sentence in test = \", test_token_count/pd_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "tokens_list = pd_train.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pant'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list[10].split()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "tokens_list = pd_train.data.tolist()\n",
    "\n",
    "tokens = []\n",
    "for each in tokens_list:\n",
    "    for i in each.split():\n",
    "        tokens.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('one', 'of', 'the'), 4941),\n",
       " (('i', 'don', 't'), 2705),\n",
       " (('this', 'movie', 'is'), 2674),\n",
       " (('of', 'the', 'film'), 2611),\n",
       " (('this', 'is', 'a'), 2379),\n",
       " (('it', 's', 'a'), 2376),\n",
       " (('a', 'lot', 'of'), 2276),\n",
       " (('of', 'the', 'movie'), 2182),\n",
       " (('some', 'of', 'the'), 1909),\n",
       " (('the', 'film', 'is'), 1872)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_trigrams = ngrams(tokens, 3)\n",
    "\n",
    "Counter(text_trigrams).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
