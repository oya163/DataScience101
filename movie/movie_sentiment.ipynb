{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Author - Oyesh Mann Singh\n",
    "    Date - 11/05/2018\n",
    "    Description \n",
    "        - Practising NLP\n",
    "        - Text preprocessing\n",
    "        - Analyzing various ML algorithms\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import unicodecsv as csv\n",
    "import unicodedata as un\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "# Checking the raw file\n",
    "file = open('./data/aclImdb/train/pos/0_9.txt')\n",
    "print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading train/text files\n",
    "pd_train = pd.read_csv('./data/aclImdb/train.csv')\n",
    "pd_test = pd.read_csv('./data/aclImdb/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ashishashishvirtualbox filehomeashishconfiglib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i get tired of my  and  year old daughters con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this movie is outrageous funny ribald sophisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i have to start saying it has been a long time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>if the very thought of arthur askey twists you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               data\n",
       "0      0  ashishashishvirtualbox filehomeashishconfiglib...\n",
       "1      1  i get tired of my  and  year old daughters con...\n",
       "2      1  this movie is outrageous funny ribald sophisti...\n",
       "3      1  i have to start saying it has been a long time...\n",
       "4      1  if the very thought of arthur askey twists you..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in train =  31408174\n",
      "Number of tokens in test =  30660597\n"
     ]
    }
   ],
   "source": [
    "train_token_count = 0\n",
    "test_token_count = 0\n",
    "\n",
    "for each_row in pd_train['data']:\n",
    "    train_token_count += len(each_row)\n",
    "    \n",
    "for each_row in pd_test['data']:\n",
    "    test_token_count += len(each_row)\n",
    "\n",
    "print(\"Number of tokens in train = \", train_token_count)\n",
    "print(\"Number of tokens in test = \", test_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Number of tokens in each sentence in train =  1256.2767089316428\n",
      "Avg Number of tokens in each sentence in test =  1226.42388\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Number of tokens in each sentence in train = \", train_token_count/pd_train.shape[0])\n",
    "print(\"Avg Number of tokens in each sentence in test = \", test_token_count/pd_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Putting all data into a list\n",
    "train_tokens_list = pd_train.data.tolist()\n",
    "test_tokens_list = pd_test.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acted'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if the token_list can be easily tokenized\n",
    "train_tokens_list[10].split()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'up'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if the token_list can be easily tokenized\n",
    "test_tokens_list[10].split()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for each in train_tokens_list:\n",
    "    for i in each.split():\n",
    "        tokens.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('one', 'of', 'the'), 4815),\n",
       " (('this', 'movie', 'is'), 2476),\n",
       " (('of', 'the', 'film'), 2363),\n",
       " (('a', 'lot', 'of'), 2255),\n",
       " (('this', 'is', 'a'), 2140),\n",
       " (('of', 'the', 'movie'), 2039),\n",
       " (('some', 'of', 'the'), 1855),\n",
       " (('is', 'one', 'of'), 1746),\n",
       " (('the', 'film', 'is'), 1686),\n",
       " (('this', 'film', 'is'), 1669)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the most commong trigrams\n",
    "text_trigrams = ngrams(tokens, 3)\n",
    "\n",
    "Counter(text_trigrams).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('is', 'one', 'of', 'the'), 1099),\n",
       " (('the', 'rest', 'of', 'the'), 1006),\n",
       " (('one', 'of', 'the', 'most'), 853),\n",
       " (('the', 'end', 'of', 'the'), 737),\n",
       " (('one', 'of', 'the', 'best'), 713),\n",
       " (('i', 'have', 'ever', 'seen'), 578),\n",
       " (('this', 'is', 'one', 'of'), 567),\n",
       " (('at', 'the', 'same', 'time'), 475),\n",
       " (('one', 'of', 'the', 'worst'), 454),\n",
       " (('at', 'the', 'end', 'of'), 431)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the most commong trigrams\n",
    "text_trigrams = ngrams(tokens, 4)\n",
    "\n",
    "Counter(text_trigrams).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138189"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the most commong trigrams\n",
    "text_unigram = ngrams(tokens, 1)\n",
    "\n",
    "c = Counter(text_unigram)\n",
    "\n",
    "# Get total count of unique words\n",
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and test list\n",
    "full_text = train_tokens_list + test_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = Counter(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 460 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fda53ce7be0>>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer.fit(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694176"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a a', 'a aa', 'a abandoned', 'a about', 'a absent', 'a absolute', 'a absolutely', 'a absolutley', 'a absurd']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "pd_train = pd_train.sample(frac=1).reset_index(drop=True)\n",
    "pd_test = pd_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>arg the shuffling dinosaurs are back to take a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>serum starts out with credits that are quite r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>admittedly i didnt have high expectations of c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>in this movie joe pesci slams dunks a basketba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>do not see this movie if you value your mind a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               data\n",
       "0      2  arg the shuffling dinosaurs are back to take a...\n",
       "1      2  serum starts out with credits that are quite r...\n",
       "2      2  admittedly i didnt have high expectations of c...\n",
       "3      2  in this movie joe pesci slams dunks a basketba...\n",
       "4      2  do not see this movie if you value your mind a..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data after shuffled\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our input train/test data\n",
    "train_vectorized = vectorizer.transform(pd_train.data)\n",
    "test_vectorized = vectorizer.transform(pd_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25001, 2694176)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of transformed vector\n",
    "print(train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with random new review\n",
    "review = [\"This movie is fine\", \"Nobody watched the movie\"]\n",
    "\n",
    "# Print the prediction of new reviews\n",
    "def print_prediction(review, est):\n",
    "    print(\"*****EVALUATE REVIEW*******\")\n",
    "    review_vectorized = vectorizer.transform(review)\n",
    "    y_pred = est.predict(review_vectorized)\n",
    "    for each_review, each_y_pred in zip(review, y_pred):\n",
    "        if each_y_pred == 1:\n",
    "            pred_review = \"Negative\"\n",
    "        else:\n",
    "            pred_review = \"Positive\"\n",
    "        print(\"{0}: {1}\".format(each_review, pred_review))\n",
    "        \n",
    "        \n",
    "def print_acc(est, acc):\n",
    "    print(\"Accuracy of {0}: {1:2.3%}\".format(est, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING SECTION STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs Rest Logisitic Regression accuracy =  0.88616\n",
      "Wall time: 7.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Logistic Regression\n",
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "ovr = OneVsRestClassifier(logreg)\n",
    "\n",
    "ovr.fit(train_vectorized, pd_train.label.values)\n",
    "ovr_acc = ovr.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print(\"One vs Rest Logisitic Regression accuracy = \", ovr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****EVALUATE REVIEW*******\n",
      "This movie is fine: Positive\n",
      "Nobody watched the movie: Negative\n"
     ]
    }
   ],
   "source": [
    "print_prediction(review, ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Cross Validation Logistic Regression\n",
    "'''\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "cv_ovr = LogisticRegression()\n",
    "\n",
    "cv_ovr = cross_validate(cv_ovr, train_vectorized, pd_train.label.values, scoring='accuracy', n_jobs=-1, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8768 0.8872 0.8908 0.8928 0.894  0.886  0.8932 0.8904 0.8828 0.894 ]\n"
     ]
    }
   ],
   "source": [
    "print(cv_ovr['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean (test) accuracy 88.88%, std 0.54.\n"
     ]
    }
   ],
   "source": [
    "print('Cross-validation mean (test) accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(cv_ovr['test_score']) * 100, np.std(cv_ovr['test_score']) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ovr = LogisticRegression()\n",
    "\n",
    "param_grid = {'C': [1, 10, 100, 1000] }\n",
    "\n",
    "ovr_grid = GridSearchCV(ovr, param_grid=param_grid, cv=5, refit=True, verbose=1)\n",
    "\n",
    "ovr_grid_fit = ovr_grid.fit(train_vectorized, pd_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression CV: 90.384%\n"
     ]
    }
   ],
   "source": [
    "ovr_grid_score = ovr_grid_fit.score(test_vectorized, pd_test.label.values)\n",
    "print_acc(acc=ovr_grid_score, est='Logistic Regression CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie was good: Positive\n",
      "There was normal acting: Negative\n"
     ]
    }
   ],
   "source": [
    "# Testing with random new review\n",
    "print_prediction(review, ovr_grid_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy 0.6966\n",
      "Wall time: 1h 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    SVM\n",
    "'''\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "my_svm = SVC()\n",
    "\n",
    "my_svm.fit(train_vectorized, pd_train.label.values)\n",
    "\n",
    "svm_acc = my_svm.score(test_vectorized, pd_test.label.values)\n",
    "print('SVM accuracy', svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is fine: Positive\n",
      "The movie is not fine: Positive\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    SVM accuracy 0.6966\n",
    "    Wall time: 1h 2min 31s\n",
    "'''\n",
    "\n",
    "# Evaluate the trained algorithm with new data\n",
    "print_prediction(review, my_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Grid Search CV SVM\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_grid = SVC()\n",
    "\n",
    "param_grid = {'C': [1, 10, 100, 1000], 'gamma': [1e-3, 1e-4]}\n",
    "\n",
    "svm_grid = GridSearchCV(svm_grid, param_grid=param_grid, cv=5, refit=True, verbose=1)\n",
    "\n",
    "svm_grid_fit = svm_grid.fit(train_vectorized, pd_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MultinomialNB: 86.336%\n",
      "*****EVALUATE REVIEW*******\n",
      "Movie was good: Negative\n",
      "There was normal acting: Negative\n",
      "Wall time: 641 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Naive Bayes MultinomialNB\n",
    "'''\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB \n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X=train_vectorized, y=pd_train.label.values)\n",
    "nb_score = nb_clf.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print_acc('MultinomialNB', nb_score)\n",
    "\n",
    "review = ['Movie was good', 'There was normal acting']\n",
    "print_prediction(review, nb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MultinomialNB: 85.084%\n",
      "*****EVALUATE REVIEW*******\n",
      "Movie was good: Negative\n",
      "There was normal acting: Negative\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Naive Bayes BernoulliNB\n",
    "'''\n",
    "\n",
    "nb_bern_clf = BernoulliNB()\n",
    "nb_bern_clf.fit(X=train_vectorized, y=pd_train.label.values)\n",
    "nb_bern_score = nb_bern_clf.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print_acc('MultinomialNB', nb_bern_score)\n",
    "\n",
    "print_prediction(review, nb_bern_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Classifier: 68.012%\n",
      "Movie was good: Positive\n",
      "There was normal acting: Negative\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    KNN Classifier\n",
    "'''\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X=train_vectorized, y=pd_train.label.values)\n",
    "knn_score = knn_clf.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print_acc('KNN Classifier', knn_score)\n",
    "\n",
    "print_prediction(review, knn_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 1s, sys: 1min 8s, total: 25min 10s\n",
      "Wall time: 24min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 24.3min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Grid Search CV kNN Classifier\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf_grid = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 2, 3, 5, 10]}\n",
    "\n",
    "knn_clf_grid = GridSearchCV(knn_clf_grid, param_grid=param_grid, cv=5, refit=True, verbose=1)\n",
    "\n",
    "knn_grid_fit = knn_clf_grid.fit(train_vectorized, pd_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GridSearch kNN: 74.669%\n",
      "*****EVALUATE REVIEW*******\n",
      "He watched a movie: Negative\n",
      "He was awarded for that kind of acting: Positive\n"
     ]
    }
   ],
   "source": [
    "print_acc(acc=knn_grid_fit.best_score_, est='GridSearch kNN')\n",
    "\n",
    "review = ['He watched a movie', 'He was awarded for that kind of acting']\n",
    "print_prediction(review, knn_grid_fit.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Perceptron Classifier: 88.244%\n",
      "Wall time: 516 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Perceptron\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "percept = Perceptron(tol=1e-3, random_state=0)\n",
    "percept.fit(X=train_vectorized, y=pd_train.label.values)\n",
    "percept_score = percept.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print_acc('Perceptron Classifier', percept_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****EVALUATE REVIEW*******\n",
      "He watched a good movie: Negative\n",
      "nothing is good: Negative\n"
     ]
    }
   ],
   "source": [
    "review = ['He watched a good movie', 'nothing is good']\n",
    "print_prediction(review, percept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oyashi/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 16.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 39s, sys: 2.45 s, total: 17min 41s\n",
      "Wall time: 16min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Grid Search CV Perceptron\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "percept_grid = Perceptron()\n",
    "\n",
    "param_grid = {'alpha':[0.0001, 0.001, 0.01, 0.1],'max_iter': [10, 50, 100, 200]}\n",
    "\n",
    "percept_grid = GridSearchCV(percept_grid, param_grid=param_grid, cv=5, refit=True, verbose=1)\n",
    "\n",
    "percept_grid_fit = percept_grid.fit(train_vectorized, pd_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GridSearch CV Perceptron Classifier: 88.984%\n",
      "*****EVALUATE REVIEW*******\n",
      "He watched a good movie: Positive\n",
      "The hall seats were empty: Negative\n"
     ]
    }
   ],
   "source": [
    "print_acc('GridSearch CV Perceptron Classifier', percept_grid_fit.best_score_)\n",
    "\n",
    "review = ['He watched a good movie', 'The hall seats were empty']\n",
    "print_prediction(review, percept_grid_fit.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MultiLayered Perceptron Classifier: 89.840%\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Multi Layered Perceptron - lbfgs\n",
    "'''\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "mlp.fit(X=train_vectorized, y=pd_train.label.values)\n",
    "mlp_score = mlp.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print_acc('MultiLayered Perceptron Classifier', mlp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****EVALUATE REVIEW*******\n",
      "He watched a stupid movie: Negative\n",
      "hall was not: Positive\n"
     ]
    }
   ],
   "source": [
    "review = ['He watched a stupid movie', '']\n",
    "print_prediction(review, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MultiLayered Perceptron Classifier: 53.448%\n",
      "Wall time: 10min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Multi Layered Perceptron - sgd\n",
    "'''\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "mlp.fit(X=train_vectorized, y=pd_train.label.values)\n",
    "mlp_score = mlp.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print_acc('MultiLayered Perceptron Classifier', mlp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****EVALUATE REVIEW*******\n",
      "He watched a good movie: Positive\n",
      "what a flop movie: Positive\n"
     ]
    }
   ],
   "source": [
    "review = ['He watched a good movie', 'what a flop movie']\n",
    "print_prediction(review, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "    Multi Layered Perceptron - adam\n",
    "'''\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "mlp.fit(X=train_vectorized, y=pd_train.label.values)\n",
    "mlp_score = mlp.score(test_vectorized, pd_test.label.values)\n",
    "\n",
    "print_acc('MultiLayered Perceptron Classifier', mlp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Grid Search CV Multi Layered Perceptron\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_grid = MLPClassifier(alpha=1e-5, random_state=1, hidden_layer_sizes=(10,5))\n",
    "\n",
    "param_grid = {'solver':['lbfgs', 'sgd', 'adam']}\n",
    "\n",
    "mlp_grid = GridSearchCV(mlp_grid, param_grid=param_grid, cv=5, refit=True, verbose=1)\n",
    "\n",
    "mlp_grid_fit = mlp_grid.fit(train_vectorized, pd_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_acc('Grid Search CV Multi Layered Perceptron', mlp_grid_fit.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Gradient Boosting Classifier\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "\n",
    "grad_boost.fit(train_vectorized, pd_train.label.values)\n",
    "\n",
    "grad_boost_score = grad_boost.score(test_vectorized, pd_test.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Visualization\n",
    "        - Collocate cloud\n",
    "        - Tag cloud\n",
    "        - Highest/Lower top 10 words\n",
    "        - Highest gram word\n",
    "        - nltk vader\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Start Deep learning\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
