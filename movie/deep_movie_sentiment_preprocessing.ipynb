{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uttam\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n",
      "C:\\Users\\uttam\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Author - Oyesh Mann Singh\n",
    "    Date - 11/30/2018\n",
    "    Description \n",
    "        - Careful text preprocessing\n",
    "        - Usage of word2vec\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import unicodecsv as csv\n",
    "import unicodedata as un\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Read all files into one corpus file\n",
    "    Break down each sentence into new line\n",
    "    Remove punctuation except selective punctuation\n",
    "    Lowercase\n",
    "    Replace numbers with <num>\n",
    "    Do not remove stop words\n",
    "    Remove '.'\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT RUN THIS SECTION TWICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    DO NOT RUN\n",
    "'''\n",
    "in_path = './data/aclImdb/data/'\n",
    "out_file = './data/raw_corpus.txt'\n",
    "\n",
    "table = dict.fromkeys(i for i in range(sys.maxunicode) \n",
    "                        if un.category(chr(i)).startswith(('P','N','S','Cf','Cn','Cc'))\n",
    "                        and i != 45 and i != 46)\n",
    "\n",
    "# Create a corpus and remove html break \n",
    "with open(out_file, 'w', encoding='utf8') as out_f:\n",
    "    for root, dirs, files in os.walk(in_path, topdown=True):\n",
    "        if(len(files) > 0):\n",
    "            for each_file in files:\n",
    "                file_path = os.path.join(root, each_file)\n",
    "                fp = open(file_path, encoding='utf-8-sig').read().replace(\"<br />\",\"\")\n",
    "                \n",
    "                fp = fp.translate(table)\n",
    "                \n",
    "                fp = re.sub(r\"(?<!\\w)[-]|[-](?!\\w)\",'',fp)\n",
    "                \n",
    "                out_f.write(fp)\n",
    "\n",
    "out_f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = './data/raw_corpus.txt'\n",
    "in_f = open(out_file, encoding='utf-8').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import gutenberg\n",
    " \n",
    "# text = \"\"\n",
    "# for file_id in gutenberg.fileids():\n",
    "#     text += gutenberg.raw(file_id)\n",
    "\n",
    "# from pprint import pprint\n",
    "# from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer, PunktToken\n",
    "\n",
    "# trainer = PunktTrainer()\n",
    "# trainer.INCLUDE_ALL_COLLOCS = True\n",
    "\n",
    "# trainer.train(text)\n",
    "# tokenizer = PunktSentenceTokenizer(trainer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr. James Ph.D. someone told me Dr. Brown is not available today.', 'I will try tomorrow.', 'I am a good boy.']\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer on a piece of text\n",
    "sentences = \"Mr. James Ph.D. someone told me Dr. Brown is not available today. I will try tomorrow. I am a good boy.\"\n",
    "sentences = tokenizer.tokenize(sentences)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_period(sents):\n",
    "    tokenized_sents = []\n",
    "    for each_sent in sents:\n",
    "        if len(each_sent) > 1 and each_sent[-1] == '.':\n",
    "            tokenized_sents.append(each_sent[:-1])\n",
    "        else:\n",
    "            tokenized_sents.append(each_sent)\n",
    "    \n",
    "    return tokenized_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "remove_period(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = tokenizer.tokenize(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aside from the terrific sea rescue sequences of which there are very few i just did not care about any of the characters.', 'most of us have ghosts in the closet and costners character are realized early on and then forgotten until much later by which time i did not care.', 'the character we should really care about is a very cocky overconfident ashton kutcher.', 'the problem is he comes off as kid who thinks hes better than anyone else around him and shows no signs of a cluttered closet.', 'his only obstacle appears to be winning over costner.', 'finally when we are well past the half way point of this stinker costner tells us all about kutchers ghosts.', 'we are told why kutcher is driven to be the best with no prior inkling or foreshadowing.', 'no magic here it was all i could do to keep from turning it off an hour in.this is an example of why the majority of action films are the same.', 'generic and boring theres really nothing worth watching here.']\n"
     ]
    }
   ],
   "source": [
    "print(sent[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a complete waste of the then barely-tapped talents of ice-t and ice cube whove each proven many times over that they are capable of acting and acting well.\n"
     ]
    }
   ],
   "source": [
    "print(sent[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = remove_period(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aside from the terrific sea rescue sequences of which there are very few i just did not care about any of the characters', 'most of us have ghosts in the closet and costners character are realized early on and then forgotten until much later by which time i did not care', 'the character we should really care about is a very cocky overconfident ashton kutcher', 'the problem is he comes off as kid who thinks hes better than anyone else around him and shows no signs of a cluttered closet', 'his only obstacle appears to be winning over costner', 'finally when we are well past the half way point of this stinker costner tells us all about kutchers ghosts', 'we are told why kutcher is driven to be the best with no prior inkling or foreshadowing', 'no magic here it was all i could do to keep from turning it off an hour in.this is an example of why the majority of action films are the same', 'generic and boring theres really nothing worth watching here']\n"
     ]
    }
   ],
   "source": [
    "print(sent[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean list as a corpus\n",
    "with open('./data/clean_corpus.pkl', 'wb') as f:\n",
    "    pickle.dump(sent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Tokenize each sentence\n",
    "'''\n",
    "import nltk\n",
    "total_sents = []\n",
    "\n",
    "for each in sent:\n",
    "    total_sents.append(each.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aside',\n",
       " 'from',\n",
       " 'the',\n",
       " 'terrific',\n",
       " 'sea',\n",
       " 'rescue',\n",
       " 'sequences',\n",
       " 'of',\n",
       " 'which',\n",
       " 'there',\n",
       " 'are',\n",
       " 'very',\n",
       " 'few',\n",
       " 'i',\n",
       " 'just',\n",
       " 'did',\n",
       " 'not',\n",
       " 'care',\n",
       " 'about',\n",
       " 'any',\n",
       " 'of',\n",
       " 'the',\n",
       " 'characters']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Creating word2vec embeddings\n",
    "'''\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "path = get_tmpfile(\"./data/word2vec.model\")\n",
    "\n",
    "model = Word2Vec(total_sents, size=50, window=5, min_count=1, workers=4)\n",
    "model.wv.save_word2vec_format('./data/word2vec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('films', 0.9444381594657898),\n",
       " ('flicks', 0.8775256276130676),\n",
       " ('comedies', 0.8527957201004028),\n",
       " ('sequels', 0.815605878829956),\n",
       " ('westerns', 0.8083510398864746),\n",
       " ('cartoons', 0.7698983550071716),\n",
       " ('classics', 0.7615748643875122),\n",
       " ('b-movies', 0.7550088167190552),\n",
       " ('shorts', 0.7373173236846924),\n",
       " ('thrillers', 0.7355096936225891)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean corpus\n",
    "with open('./data/clean_corpus.pkl', 'rb') as f:\n",
    "    mynewlist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aside from the terrific sea rescue sequences of which there are very few i just did not care about any of the characters', 'most of us have ghosts in the closet and costners character are realized early on and then forgotten until much later by which time i did not care', 'the character we should really care about is a very cocky overconfident ashton kutcher', 'the problem is he comes off as kid who thinks hes better than anyone else around him and shows no signs of a cluttered closet', 'his only obstacle appears to be winning over costner', 'finally when we are well past the half way point of this stinker costner tells us all about kutchers ghosts', 'we are told why kutcher is driven to be the best with no prior inkling or foreshadowing', 'no magic here it was all i could do to keep from turning it off an hour in.this is an example of why the majority of action films are the same', 'generic and boring theres really nothing worth watching here']\n"
     ]
    }
   ],
   "source": [
    "print(mynewlist[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
